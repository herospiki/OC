{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import arange, argmin, argmax\n",
    "import pandas_flavor as pf\n",
    "import tqdm\n",
    "import re\n",
    "from random import random\n",
    "from time import time\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../../gen_data/data_to_train.pkl')\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pf.register_dataframe_method\n",
    "def add_row(df, row):\n",
    "    df.loc[len(df)] = row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'initialisation des tables pour le stockage des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tables():\n",
    "    table_scores = PrettyTable()\n",
    "    scores_df = pd.DataFrame([], columns=[\"model name\", \"step\", \"time\",\n",
    "                             \"roc AUC score\", \"accuracy\", \"F2-score\", \"precision\", \"recall\"])\n",
    "    table_scores.field_names = [\"model name\", \"step\", \"time\",\n",
    "                                \"roc AUC score\", \"accuracy\",  \"F2-score\", \"precision\", \"recall\"]\n",
    "    return scores_df, table_scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour extraire un sample équilibré des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_for_testing(data,ratio):\n",
    "    data_0 = data[data.TARGET == 0]\n",
    "    data_1 = data[data.TARGET == 1]\n",
    "    data_0 = data_0.sample(int(round(len(data_0)*ratio, 0)))\n",
    "    data_1 = data_1.sample(int(round(len(data_1)*ratio, 0)))\n",
    "    data = data_1.append(data_0)\n",
    "    del data_0, data_1\n",
    "    gc.collect()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation et optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_and_log(model_name, model_pipeline,step, time, x_test, y_test, scores_df, table_scores):\n",
    "    test_pred = model_pipeline.predict(x_test)\n",
    "    test_pred_proba = model_pipeline.predict_proba(x_test)\n",
    "\n",
    "    auc_score = roc_auc_score(y_test, test_pred_proba[:, 1])\n",
    "    accuracy = accuracy_score(y_test, test_pred)\n",
    "    F2_score = fbeta_score(y_test, test_pred, beta=2)\n",
    "    precision = precision_score(y_test, test_pred)\n",
    "    recall = recall_score(y_test, test_pred)\n",
    "\n",
    "    scores_df.add_row([model_name, step, time, auc_score,accuracy, F2_score, precision, recall])\n",
    "    table_scores.add_row([model_name, step, time, auc_score,accuracy, F2_score, precision, recall])\n",
    "    #print('Confusion matrix:\\n', confusion_matrix(y_test, test_pred))\n",
    "    return scores_df, table_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_pipeline, x_test, y_test):\n",
    "    # prediction\n",
    "    test_pred = model_pipeline.predict(x_test)\n",
    "    test_pred_proba = model_pipeline.predict_proba(x_test)\n",
    "    print('Roc auc score : {:.4f}'.format(\n",
    "        roc_auc_score(y_test, test_pred_proba[:, 1])))\n",
    "    print('F2-score : {:.4f}'.format(fbeta_score(y_test, test_pred, beta=2)))\n",
    "    print('Accuracy :{:.4f}'.format(accuracy_score(y_test, test_pred)))\n",
    "    print('Precision :{:.4f}'.format(precision_score(y_test, test_pred)))\n",
    "    print('Recall : {:.4f}'.format( recall_score(y_test, test_pred)))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    " return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "def evaluate_model_with_threshold(model_pipeline,x_test, y_test, threshold):\n",
    "    test_pred_proba = model_pipeline.predict_proba(x_test)\n",
    "    test_pred_th = to_labels(test_pred_proba, threshold)[::,1]\n",
    "    print('Roc auc score : {:.4f}'.format(roc_auc_score(y_test, test_pred_th)))\n",
    "    print('F2-score : {:.4f}'.format(fbeta_score(y_test, test_pred_th, beta=2)))\n",
    "    print('Accuracy :{:.4f}'.format(accuracy_score(y_test, test_pred_th)))\n",
    "    print('Precision :{:.4f}'.format(precision_score(y_test, test_pred_th)))\n",
    "    print('Recall : {:.4f}'.format( recall_score(y_test, test_pred_th)))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, test_pred_th))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scorer utilisé : fbeta_score avec beta = 2 pour donner plus de poids à la classe positive qui est minoritaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de plusieurs algorithmes sur un sous-ensemble des données "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend la moitié des données uniquement pour accélérer l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = get_sample_for_testing(data, 0.5)\n",
    "y_sample = data_sample[['TARGET']]\n",
    "X_sample = data_sample.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "features = X_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_train, X_sample_valid, y_sample_train, y_sample_valid = train_test_split(\n",
    "    X_sample, y_sample, test_size=0.20, random_state=42, stratify=y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results for Dummy Classification \n",
      "-------------------------------\n",
      "Roc auc score : 0.4999\n",
      "F2-score : 0.0812\n",
      "Accuracy :0.8528\n",
      "Precision :0.0822\n",
      "Recall : 0.0810\n",
      "Confusion matrix:\n",
      " [[104093   8981]\n",
      " [  9126    804]]\n",
      "===============================\n",
      "Validation Results for Dummy Classification \n",
      "-------------------------------\n",
      "Roc auc score : 0.5003\n",
      "F2-score : 0.0757\n",
      "Accuracy :0.8527\n",
      "Precision :0.0772\n",
      "Recall : 0.0753\n",
      "Confusion matrix:\n",
      " [[26033  2236]\n",
      " [ 2295   187]]\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf.fit(X_sample_train,y_sample_train)\n",
    "y_dummy_pred = dummy_clf.predict(X_sample_valid)\n",
    "\n",
    "print('Training Results for Dummy Classification ')\n",
    "print('-------------------------------')\n",
    "evaluate_model(dummy_clf,X_sample_train, y_sample_train)\n",
    "print('===============================')\n",
    "print('Validation Results for Dummy Classification ')\n",
    "print('-------------------------------')\n",
    "evaluate_model(dummy_clf,X_sample_valid, y_sample_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et évaluation plusieurs classifieurs binaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour comparer quelques modèles, sans optimisation, afin de choisir le meilleur modèle à optimiser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y, with_smote=False, worf = False):\n",
    "    scores_df, table_scores = init_tables()\n",
    "    scale_pos_weight = Counter(y['TARGET'])[0]/Counter(y['TARGET'])[1]\n",
    "    \n",
    "    classifiers = [\n",
    "            ('Logistic Regression', LogisticRegression(class_weight='balanced')),\n",
    "            ('RandomForest', RandomForestClassifier(class_weight='balanced')),\n",
    "            ('XGBoost', XGBClassifier(scale_pos_weight=scale_pos_weight)),\n",
    "            ('Light GBM', LGBMClassifier(objective='binary', scale_pos_weight=scale_pos_weight))\n",
    "            ]\n",
    "    if with_smote & worf : \n",
    "        classifiers = [\n",
    "            ('Logistic Regression', LogisticRegression()),\n",
    "            ('XGBoost', XGBClassifier()),\n",
    "            ('Light GBM', LGBMClassifier(objective='binary'))\n",
    "            ]\n",
    "    if ((with_smote == False) and (worf == True)) : \n",
    "        classifiers =  [\n",
    "            ('Logistic Regression', LogisticRegression(class_weight='balanced')),\n",
    "            ('XGBoost', XGBClassifier(scale_pos_weight=scale_pos_weight)),\n",
    "            ('Light GBM', LGBMClassifier(objective='binary', scale_pos_weight=scale_pos_weight))\n",
    "            ]\n",
    "\n",
    "    skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=100)\n",
    "\n",
    "    for clf_name, clf in tqdm.tqdm(classifiers):\n",
    "        print(clf_name)\n",
    "        print('===============================')\n",
    "        # Entraîner le classifieur sur les données d'entraînement\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaler', RobustScaler()),\n",
    "            ('classifier', clf)\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(skfolds.split(X, y)):\n",
    "            start = time()\n",
    "            X_train = X.iloc[train_index]\n",
    "            y_train = y.iloc[train_index]\n",
    "            X_test = X.iloc[test_index]\n",
    "            y_test = y.iloc[test_index]\n",
    "            if with_smote:\n",
    "                over_only = SMOTE()\n",
    "                print('Before sampling')\n",
    "                print(Counter(y_train['TARGET']))\n",
    "\n",
    "                # transform the dataset\n",
    "\n",
    "                X_train_re, y_train_re = over_only.fit_resample(\n",
    "                    X_train, y_train)\n",
    "                print('After sampling')\n",
    "                print(Counter(y_train_re['TARGET']))\n",
    "                curr_clf = pipeline.fit(X_train_re, y_train_re)\n",
    "            else:\n",
    "                curr_clf = pipeline.fit(X_train, y_train)\n",
    "\n",
    "            duration = time()-start\n",
    "    \n",
    "            print(clf_name + ' -- fold n°' + str(i))\n",
    "            print('-------------------------------')\n",
    "            scores_df, table_scores = evaluate_and_log(\n",
    "                clf_name, curr_clf, 'train', duration, X_train, y_train, scores_df, table_scores)\n",
    "            scores_df, table_scores = evaluate_and_log(\n",
    "                clf_name, curr_clf, 'test', duration, X_test, y_test, scores_df, table_scores)\n",
    "  \n",
    "        print('===============================')\n",
    "       \n",
    "    return scores_df, table_scores\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Random Forest est très long à s'exécuter et ses résultats sur l'apprentissage montre une grosse tendance à l'overfitting avec ses paramètres par défaut. Aussi, je l'exclue de la recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "===============================\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "Logistic Regression -- fold n°0\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "Logistic Regression -- fold n°1\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Logistic Regression -- fold n°2\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Logistic Regression -- fold n°3\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Logistic Regression -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:51<01:42, 51.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "XGBoost\n",
      "===============================\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "XGBoost -- fold n°0\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "XGBoost -- fold n°1\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "XGBoost -- fold n°2\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "XGBoost -- fold n°3\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "XGBoost -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [04:59<02:47, 167.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Light GBM\n",
      "===============================\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "Light GBM -- fold n°0\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113075, 1.0: 9929})\n",
      "After sampling\n",
      "Counter({1.0: 113075, 0.0: 113075})\n",
      "Light GBM -- fold n°1\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Light GBM -- fold n°2\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Light GBM -- fold n°3\n",
      "-------------------------------\n",
      "Before sampling\n",
      "Counter({0.0: 113074, 1.0: 9930})\n",
      "After sampling\n",
      "Counter({1.0: 113074, 0.0: 113074})\n",
      "Light GBM -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:58<00:00, 119.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores_df, table_scores = train_and_evaluate(X_sample, y_sample, with_smote=True, worf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>roc AUC score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Light GBM</th>\n",
       "      <th>test</th>\n",
       "      <td>49.479225</td>\n",
       "      <td>0.750906</td>\n",
       "      <td>0.918903</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.461949</td>\n",
       "      <td>0.025460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>49.479225</td>\n",
       "      <td>0.794240</td>\n",
       "      <td>0.920253</td>\n",
       "      <td>0.042961</td>\n",
       "      <td>0.605224</td>\n",
       "      <td>0.034865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>test</th>\n",
       "      <td>45.684061</td>\n",
       "      <td>0.746111</td>\n",
       "      <td>0.689825</td>\n",
       "      <td>0.410694</td>\n",
       "      <td>0.160659</td>\n",
       "      <td>0.672414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>45.684061</td>\n",
       "      <td>0.748884</td>\n",
       "      <td>0.691122</td>\n",
       "      <td>0.413501</td>\n",
       "      <td>0.161896</td>\n",
       "      <td>0.676362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBoost</th>\n",
       "      <th>test</th>\n",
       "      <td>239.488193</td>\n",
       "      <td>0.738615</td>\n",
       "      <td>0.917414</td>\n",
       "      <td>0.063054</td>\n",
       "      <td>0.410094</td>\n",
       "      <td>0.052046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>239.488193</td>\n",
       "      <td>0.885532</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.174873</td>\n",
       "      <td>0.883814</td>\n",
       "      <td>0.145666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 time  roc AUC score  accuracy  F2-score  \\\n",
       "model name          step                                                   \n",
       "Light GBM           test    49.479225       0.750906  0.918903  0.031383   \n",
       "                    train   49.479225       0.794240  0.920253  0.042961   \n",
       "Logistic Regression test    45.684061       0.746111  0.689825  0.410694   \n",
       "                    train   45.684061       0.748884  0.691122  0.413501   \n",
       "XGBoost             test   239.488193       0.738615  0.917414  0.063054   \n",
       "                    train  239.488193       0.885532  0.929487  0.174873   \n",
       "\n",
       "                           precision    recall  \n",
       "model name          step                        \n",
       "Light GBM           test    0.461949  0.025460  \n",
       "                    train   0.605224  0.034865  \n",
       "Logistic Regression test    0.160659  0.672414  \n",
       "                    train   0.161896  0.676362  \n",
       "XGBoost             test    0.410094  0.052046  \n",
       "                    train   0.883814  0.145666  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores_df = scores_df.groupby(by=['model name', 'step']).agg(\n",
    "    {'time': sum, 'roc AUC score': 'mean', 'accuracy': 'mean', 'F2-score': 'mean', 'precision': 'mean', 'recall': 'mean'})\n",
    "\n",
    "mean_scores_df.to_pickle('../../gen_data/half_data_class_with_smote_scores_df.pkl')\n",
    "mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>roc AUC score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Light GBM</th>\n",
       "      <th>test</th>\n",
       "      <td>49.479225</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.032819</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>49.479225</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>test</th>\n",
       "      <td>45.684061</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.007364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>45.684061</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.006779</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.004636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBoost</th>\n",
       "      <th>test</th>\n",
       "      <td>239.488193</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>239.488193</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 time  roc AUC score  accuracy  F2-score  \\\n",
       "model name          step                                                   \n",
       "Light GBM           test    49.479225       0.003405  0.000330  0.003588   \n",
       "                    train   49.479225       0.001172  0.000073  0.002800   \n",
       "Logistic Regression test    45.684061       0.005647  0.008109  0.006112   \n",
       "                    train   45.684061       0.002662  0.006779  0.003888   \n",
       "XGBoost             test   239.488193       0.004237  0.000479  0.001138   \n",
       "                    train  239.488193       0.003427  0.000349  0.004555   \n",
       "\n",
       "                           precision    recall  \n",
       "model name          step                        \n",
       "Light GBM           test    0.032819  0.002956  \n",
       "                    train   0.003446  0.002304  \n",
       "Logistic Regression test    0.003933  0.007364  \n",
       "                    train   0.002992  0.004636  \n",
       "XGBoost             test    0.019491  0.000958  \n",
       "                    train   0.009786  0.003932  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scores_df = scores_df.groupby(by=['model name', 'step']).agg(\n",
    "    {'time': sum, 'roc AUC score': 'std', 'accuracy': 'std', 'F2-score': 'std', 'precision': 'std', 'recall': 'std'})\n",
    "\n",
    "std_scores_df.to_pickle('../../gen_data/half_data_class_with_smote_std_scores_df.pkl')\n",
    "std_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "===============================\n",
      "Logistic Regression -- fold n°0\n",
      "-------------------------------\n",
      "Logistic Regression -- fold n°1\n",
      "-------------------------------\n",
      "Logistic Regression -- fold n°2\n",
      "-------------------------------\n",
      "Logistic Regression -- fold n°3\n",
      "-------------------------------\n",
      "Logistic Regression -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:24<00:48, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "XGBoost\n",
      "===============================\n",
      "XGBoost -- fold n°0\n",
      "-------------------------------\n",
      "XGBoost -- fold n°1\n",
      "-------------------------------\n",
      "XGBoost -- fold n°2\n",
      "-------------------------------\n",
      "XGBoost -- fold n°3\n",
      "-------------------------------\n",
      "XGBoost -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [02:09<01:11, 71.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "Light GBM\n",
      "===============================\n",
      "Light GBM -- fold n°0\n",
      "-------------------------------\n",
      "Light GBM -- fold n°1\n",
      "-------------------------------\n",
      "Light GBM -- fold n°2\n",
      "-------------------------------\n",
      "Light GBM -- fold n°3\n",
      "-------------------------------\n",
      "Light GBM -- fold n°4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:37<00:00, 52.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores_df, table_scores = train_and_evaluate(X_sample, y_sample, with_smote=False, worf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>roc AUC score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Light GBM</th>\n",
       "      <th>test</th>\n",
       "      <td>18.994570</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>0.720165</td>\n",
       "      <td>0.422262</td>\n",
       "      <td>0.173809</td>\n",
       "      <td>0.657107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>18.994570</td>\n",
       "      <td>0.842296</td>\n",
       "      <td>0.739516</td>\n",
       "      <td>0.502642</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.783496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>test</th>\n",
       "      <td>18.758992</td>\n",
       "      <td>0.751658</td>\n",
       "      <td>0.690690</td>\n",
       "      <td>0.416691</td>\n",
       "      <td>0.162751</td>\n",
       "      <td>0.683210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>18.758992</td>\n",
       "      <td>0.754639</td>\n",
       "      <td>0.691218</td>\n",
       "      <td>0.419551</td>\n",
       "      <td>0.163798</td>\n",
       "      <td>0.688185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBoost</th>\n",
       "      <th>test</th>\n",
       "      <td>96.899516</td>\n",
       "      <td>0.736341</td>\n",
       "      <td>0.771981</td>\n",
       "      <td>0.392226</td>\n",
       "      <td>0.186352</td>\n",
       "      <td>0.541977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>96.899516</td>\n",
       "      <td>0.924669</td>\n",
       "      <td>0.823102</td>\n",
       "      <td>0.633461</td>\n",
       "      <td>0.298332</td>\n",
       "      <td>0.880862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time  roc AUC score  accuracy  F2-score  \\\n",
       "model name          step                                                  \n",
       "Light GBM           test   18.994570       0.758914  0.720165  0.422262   \n",
       "                    train  18.994570       0.842296  0.739516  0.502642   \n",
       "Logistic Regression test   18.758992       0.751658  0.690690  0.416691   \n",
       "                    train  18.758992       0.754639  0.691218  0.419551   \n",
       "XGBoost             test   96.899516       0.736341  0.771981  0.392226   \n",
       "                    train  96.899516       0.924669  0.823102  0.633461   \n",
       "\n",
       "                           precision    recall  \n",
       "model name          step                        \n",
       "Light GBM           test    0.173809  0.657107  \n",
       "                    train   0.206522  0.783496  \n",
       "Logistic Regression test    0.162751  0.683210  \n",
       "                    train   0.163798  0.688185  \n",
       "XGBoost             test    0.186352  0.541977  \n",
       "                    train   0.298332  0.880862  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores_df = scores_df.groupby(by=['model name', 'step']).agg(\n",
    "    {'time': sum, 'roc AUC score': 'mean', 'accuracy': 'mean', 'F2-score': 'mean', 'precision': 'mean', 'recall': 'mean'})\n",
    "\n",
    "mean_scores_df.to_pickle('../../gen_data/half_data_class_without_smote_scores_df.pkl')\n",
    "mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>roc AUC score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F2-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Light GBM</th>\n",
       "      <th>test</th>\n",
       "      <td>18.994570</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.009322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>18.994570</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.001435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Logistic Regression</th>\n",
       "      <th>test</th>\n",
       "      <td>18.758992</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.007598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>18.758992</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XGBoost</th>\n",
       "      <th>test</th>\n",
       "      <td>96.899516</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.012021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>96.899516</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.009022</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.009281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time  roc AUC score  accuracy  F2-score  \\\n",
       "model name          step                                                  \n",
       "Light GBM           test   18.994570       0.003099  0.002719  0.005004   \n",
       "                    train  18.994570       0.000481  0.000198  0.000855   \n",
       "Logistic Regression test   18.758992       0.002601  0.002860  0.004076   \n",
       "                    train  18.758992       0.000540  0.000783  0.000654   \n",
       "XGBoost             test   96.899516       0.004019  0.003737  0.006266   \n",
       "                    train  96.899516       0.004320  0.003728  0.009022   \n",
       "\n",
       "                           precision    recall  \n",
       "model name          step                        \n",
       "Light GBM           test    0.002032  0.009322  \n",
       "                    train   0.000330  0.001435  \n",
       "Logistic Regression test    0.001740  0.007598  \n",
       "                    train   0.000285  0.001726  \n",
       "XGBoost             test    0.002647  0.012021  \n",
       "                    train   0.005876  0.009281  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scores_df = scores_df.groupby(by=['model name', 'step']).agg(\n",
    "    {'time': sum, 'roc AUC score': 'std', 'accuracy': 'std', 'F2-score': 'std', 'precision': 'std', 'recall': 'std'})\n",
    "\n",
    "std_scores_df.to_pickle('../../gen_data/half_data_class_without_smote_std_scores_df.pkl')\n",
    "std_scores_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais maintenant comparer les résultats obtenus sur l'apprentissage avec l'ensemble complet, pour la régression logistique et Light GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifiers = data[['SK_ID_CURR']]\n",
    "y = data[['TARGET']]\n",
    "X = data.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "features = X.columns\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20, random_state=100, stratify = y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "                 ('scaler', RobustScaler()),\n",
    "                 ('model', LogisticRegression(class_weight='balanced'))])\n",
    "               \n",
    "default_logreg_clf = pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for Base Log Reg\n",
      "-------------------------------\n",
      "Roc auc score : 0.7534\n",
      "F2-score : 0.4191\n",
      "Accuracy :0.6902\n",
      "Precision :0.1634\n",
      "Recall : 0.6886\n",
      "Confusion matrix:\n",
      " [[156116  70032]\n",
      " [  6185  13675]]\n",
      "===============================\n",
      "Validation results for Base Log Reg\n",
      "-------------------------------\n",
      "Roc auc score : 0.7506\n",
      "F2-score : 0.4147\n",
      "Accuracy :0.6896\n",
      "Precision :0.1618\n",
      "Recall : 0.6808\n",
      "Confusion matrix:\n",
      " [[39030 17508]\n",
      " [ 1585  3380]]\n"
     ]
    }
   ],
   "source": [
    "print('Training results for Base Log Reg')\n",
    "print('-------------------------------')\n",
    "evaluate_model(default_logreg_clf, X_train, y_train)\n",
    "print('===============================')\n",
    "print('Validation results for Base Log Reg')\n",
    "print('-------------------------------')\n",
    "evaluate_model(default_logreg_clf, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM - Avant optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.38710976837865"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = Counter(y_train['TARGET'])[0]/Counter(y_train['TARGET'])[1]\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('scaler', RobustScaler()),\n",
    "                 ('model', LGBMClassifier(objective='binary', scale_pos_weight = scale_pos_weight))])\n",
    "\n",
    "default_lgbm_clf = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for Base LGBM\n",
      "-------------------------------\n",
      "Roc auc score : 0.8085\n",
      "F2-score : 0.4673\n",
      "Accuracy :0.7162\n",
      "Precision :0.1866\n",
      "Recall : 0.7490\n",
      "Confusion matrix:\n",
      " [[161310  64838]\n",
      " [  4985  14875]]\n",
      "===============================\n",
      "Validation results for Base LGBM\n",
      "-------------------------------\n",
      "Roc auc score : 0.7612\n",
      "F2-score : 0.4252\n",
      "Accuracy :0.7054\n",
      "Precision :0.1699\n",
      "Recall : 0.6814\n",
      "Confusion matrix:\n",
      " [[40004 16534]\n",
      " [ 1582  3383]]\n"
     ]
    }
   ],
   "source": [
    "print('Training results for Base LGBM')\n",
    "print('-------------------------------')\n",
    "evaluate_model(default_lgbm_clf, X_train, y_train)\n",
    "print('===============================')\n",
    "print('Validation results for Base LGBM')\n",
    "print('-------------------------------')\n",
    "evaluate_model(default_lgbm_clf, X_valid, y_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation de LGBM avec GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class lightgbm.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=None, importance_type='split', **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(estimator: Any, param_grid: Any, *, scoring: Any | None = None, n_jobs: Any | None = None, refit: bool = True, cv: Any | None = None, verbose: int = 0, pre_dispatch: str = \"2*n_jobs\", error_score: float = np.nan, return_train_score: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (246008, 100), Validation set shape: (61503, 100)\n",
      "Train counting: Counter({0.0: 226148, 1.0: 19860}), Validation counting: Counter({0.0: 56538, 1.0: 4965})\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5\n",
      "[CV 1/5; 1/9] END lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5;, score=(train=0.548, test=0.415) total time=  12.1s\n",
      "[CV 2/5; 1/9] START lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5\n",
      "[CV 2/5; 1/9] END lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5;, score=(train=0.546, test=0.425) total time=  11.5s\n",
      "[CV 3/5; 1/9] START lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5\n",
      "[CV 3/5; 1/9] END lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5;, score=(train=0.547, test=0.420) total time=  13.2s\n",
      "[CV 4/5; 1/9] START lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5\n",
      "[CV 4/5; 1/9] END lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5;, score=(train=0.549, test=0.426) total time=  13.6s\n",
      "[CV 5/5; 1/9] START lgbm__colsample_bytree=0.5, lgbm__learning_rate=0.1, lgbm__n_estimators=300, lgbm__num_leaves=31, lgbm__reg_alpha=0.1, lgbm__reg_lambda=0.1, lgbm__subsample=0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 42\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m#Grid search\u001b[39;00m\n\u001b[0;32m     33\u001b[0m grid_cv \u001b[39m=\u001b[39m GridSearchCV(classifier_pipe,\n\u001b[0;32m     34\u001b[0m                     param_grid,\n\u001b[0;32m     35\u001b[0m                     scoring\u001b[39m=\u001b[39m ftwo_scorer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m                     verbose\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[0;32m     40\u001b[0m                     )\n\u001b[1;32m---> 42\u001b[0m grid_cv\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBEST SCORE: \u001b[39m\u001b[39m{\u001b[39;00mgrid_cv\u001b[39m.\u001b[39mbest_score_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m best_model \u001b[39m=\u001b[39m grid_cv\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\imblearn\\pipeline.py:272\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    271\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 272\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, yt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[39m=\u001b[39m (valid_x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_le\u001b[39m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, _y, sample_weight\u001b[39m=\u001b[39;49msample_weight, init_score\u001b[39m=\u001b[39;49minit_score, eval_set\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    968\u001b[0m             eval_names\u001b[39m=\u001b[39;49meval_names, eval_sample_weight\u001b[39m=\u001b[39;49meval_sample_weight,\n\u001b[0;32m    969\u001b[0m             eval_class_weight\u001b[39m=\u001b[39;49meval_class_weight, eval_init_score\u001b[39m=\u001b[39;49meval_init_score,\n\u001b[0;32m    970\u001b[0m             eval_metric\u001b[39m=\u001b[39;49meval_metric, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m    971\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose, feature_name\u001b[39m=\u001b[39;49mfeature_name, categorical_feature\u001b[39m=\u001b[39;49mcategorical_feature,\n\u001b[0;32m    972\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks, init_model\u001b[39m=\u001b[39;49minit_model)\n\u001b[0;32m    973\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[39m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[39m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m    749\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    750\u001b[0m     train_set\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m    751\u001b[0m     num_boost_round\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_estimators,\n\u001b[0;32m    752\u001b[0m     valid_sets\u001b[39m=\u001b[39;49mvalid_sets,\n\u001b[0;32m    753\u001b[0m     valid_names\u001b[39m=\u001b[39;49meval_names,\n\u001b[0;32m    754\u001b[0m     fobj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fobj,\n\u001b[0;32m    755\u001b[0m     feval\u001b[39m=\u001b[39;49meval_metrics_callable,\n\u001b[0;32m    756\u001b[0m     init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m    757\u001b[0m     feature_name\u001b[39m=\u001b[39;49mfeature_name,\n\u001b[0;32m    758\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    759\u001b[0m )\n\u001b[0;32m    761\u001b[0m \u001b[39mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evals_result \u001b[39m=\u001b[39m evals_result\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sophie\\Documents\\Data Scientist\\Projet 7\\.venv\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[0;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting LightGBM. Train shape: {}, Validation set shape: {}\".format(\n",
    "        X_train.shape, X_valid.shape))\n",
    "print(\"Train counting: {}, Validation counting: {}\".format(\n",
    "        Counter(y_train['TARGET']), Counter(y_valid['TARGET'])))\n",
    "\n",
    "classifier_pipe = Pipeline(steps=(['scaler', RobustScaler()],\n",
    "                                ['lgbm', LGBMClassifier(objective='binary', scale_pos_weight=scale_pos_weight)]))\n",
    "\n",
    "search_params = {\n",
    "   # 'lgbm__learning_rate': [0.1, 0.05],\n",
    "   # 'lgbm__num_leaves': [31, 63, 127],\n",
    "   # 'lgbm__n_estimators': [200, 300, 500],\n",
    "   # 'lgbm__subsample': [0.5, 0.8, 1.0],\n",
    "   # 'lgbm__colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    'lgbm__reg_alpha': [0.1, 0.5, 1.0],\n",
    "    'lgbm__reg_lambda': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'lgbm__learning_rate': [0.1],\n",
    "    'lgbm__num_leaves': [31],\n",
    "    'lgbm__n_estimators': [300],\n",
    "    'lgbm__subsample': [0.5],\n",
    "    'lgbm__colsample_bytree': [0.5],\n",
    "    #'lgbm__reg_alpha': [0.1, 0.5, 1.0],\n",
    "    #'lgbm__reg_lambda': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "param_grid = {**search_params, **fixed_params}\n",
    "\n",
    "folds = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "#Grid search\n",
    "grid_cv = GridSearchCV(classifier_pipe,\n",
    "                    param_grid,\n",
    "                    scoring= ftwo_scorer,\n",
    "                    cv=folds,\n",
    "                    n_jobs=1,\n",
    "                    return_train_score=True,\n",
    "                    verbose=10\n",
    "                    )\n",
    "\n",
    "grid_cv.fit(X_train,y_train)\n",
    "\n",
    "print(f\"BEST SCORE: {grid_cv.best_score_}\")\n",
    "best_model = grid_cv.best_estimator_\n",
    "print(grid_cv.best_params_)\n",
    "    # model can be saved, used for predictions or scoring\n",
    "best_model = grid_cv.best_estimator_\n",
    "\n",
    "filename = '../../gen_data/final_model.sav'\n",
    "pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for best model\n",
      "-------------------------------\n",
      "Roc auc score : 0.8592\n",
      "F2-score : 0.5271\n",
      "Accuracy :0.7578\n",
      "Precision :0.2225\n",
      "Recall : 0.8014\n",
      "Confusion matrix:\n",
      " [[170519  55629]\n",
      " [  3944  15916]]\n",
      "===============================\n",
      "Validation results for best model\n",
      "-------------------------------\n",
      "Roc auc score : 0.7591\n",
      "F2-score : 0.4214\n",
      "Accuracy :0.7326\n",
      "Precision :0.1781\n",
      "Recall : 0.6399\n",
      "Confusion matrix:\n",
      " [[41880 14658]\n",
      " [ 1788  3177]]\n"
     ]
    }
   ],
   "source": [
    "print('Training results for best model')\n",
    "print('-------------------------------')\n",
    "evaluate_model(best_model, X_train, y_train)\n",
    "print('===============================')\n",
    "print('Validation results for best model')\n",
    "print('-------------------------------')\n",
    "evaluate_model(best_model, X_valid, y_valid)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche du seuil de probabilité permettant de maximiser le gain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions de calculs du gain et de représentation graphique de la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    " return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "# à maximiser\n",
    "def gain(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Par exemple\n",
    "    gain =  2* tn - 10*fn\n",
    "    return gain\n",
    "\n",
    "def plot_gain_scores(threshold_array, gain_scores, accuracy_scores, recall_scores) :\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=threshold_array, y=accuracy_scores, name=\"accuracy\"),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=threshold_array, y=recall_scores, name=\"recall\"),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=threshold_array, y=gain_scores, name=\"gain\"),\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=\"Gain versus accuracy et recall\"\n",
    "    )\n",
    "\n",
    "    # Set x-axis title\n",
    "    fig.update_xaxes(title_text=\"Seuil de probabilité\")\n",
    "\n",
    "    # Set y-axes titles\n",
    "    fig.update_yaxes(title_text=\"scores\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"gain\", secondary_y=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seuil=0.626, gain maximum=388420.00000\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = best_model.predict_proba(X)[::,1]\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "threshold_array = np.linspace(0, 1, 100)\n",
    "\n",
    "gain_scores = [gain(y, to_labels(y_pred_proba, t)) for t in threshold_array]\n",
    "recall_scores = [recall_score(y, to_labels(y_pred_proba, t)) for t in threshold_array]\n",
    "accuracy_scores = [accuracy_score(y, to_labels(y_pred_proba, t)) for t in threshold_array]\n",
    "\n",
    "# récupération du meilleur seuil (maximisation du gain)\n",
    "\n",
    "maxgain_ix = argmax(gain_scores)\n",
    "best_threshold = threshold_array[maxgain_ix]\n",
    "max_gain = gain_scores[maxgain_ix]\n",
    "\n",
    "print('Seuil=%.3f, gain maximum=%.5f' % (best_threshold, max_gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "precision",
         "type": "scatter",
         "x": [
          0,
          0.010101010101010102,
          0.020202020202020204,
          0.030303030303030304,
          0.04040404040404041,
          0.05050505050505051,
          0.06060606060606061,
          0.07070707070707072,
          0.08080808080808081,
          0.09090909090909091,
          0.10101010101010102,
          0.11111111111111112,
          0.12121212121212122,
          0.13131313131313133,
          0.14141414141414144,
          0.15151515151515152,
          0.16161616161616163,
          0.17171717171717174,
          0.18181818181818182,
          0.19191919191919193,
          0.20202020202020204,
          0.21212121212121213,
          0.22222222222222224,
          0.23232323232323235,
          0.24242424242424243,
          0.25252525252525254,
          0.26262626262626265,
          0.27272727272727276,
          0.2828282828282829,
          0.29292929292929293,
          0.30303030303030304,
          0.31313131313131315,
          0.32323232323232326,
          0.33333333333333337,
          0.3434343434343435,
          0.3535353535353536,
          0.36363636363636365,
          0.37373737373737376,
          0.38383838383838387,
          0.393939393939394,
          0.4040404040404041,
          0.4141414141414142,
          0.42424242424242425,
          0.43434343434343436,
          0.4444444444444445,
          0.4545454545454546,
          0.4646464646464647,
          0.4747474747474748,
          0.48484848484848486,
          0.494949494949495,
          0.5050505050505051,
          0.5151515151515152,
          0.5252525252525253,
          0.5353535353535354,
          0.5454545454545455,
          0.5555555555555556,
          0.5656565656565657,
          0.5757575757575758,
          0.5858585858585859,
          0.595959595959596,
          0.6060606060606061,
          0.6161616161616162,
          0.6262626262626263,
          0.6363636363636365,
          0.6464646464646465,
          0.6565656565656566,
          0.6666666666666667,
          0.6767676767676768,
          0.686868686868687,
          0.696969696969697,
          0.7070707070707072,
          0.7171717171717172,
          0.7272727272727273,
          0.7373737373737375,
          0.7474747474747475,
          0.7575757575757577,
          0.7676767676767677,
          0.7777777777777778,
          0.787878787878788,
          0.797979797979798,
          0.8080808080808082,
          0.8181818181818182,
          0.8282828282828284,
          0.8383838383838385,
          0.8484848484848485,
          0.8585858585858587,
          0.8686868686868687,
          0.8787878787878789,
          0.888888888888889,
          0.8989898989898991,
          0.9090909090909092,
          0.9191919191919192,
          0.9292929292929294,
          0.9393939393939394,
          0.9494949494949496,
          0.9595959595959597,
          0.9696969696969697,
          0.9797979797979799,
          0.98989898989899,
          1
         ],
         "xaxis": "x",
         "y": [
          0.08072881945686496,
          0.08073984694391954,
          0.08084456400669607,
          0.08111570450497557,
          0.08158770234197273,
          0.08228517613351859,
          0.08315760182649014,
          0.0842687274222544,
          0.08554784025179807,
          0.08695362262892839,
          0.08847489602538267,
          0.09015721494543931,
          0.09190103537371973,
          0.09375889593605174,
          0.09573497614583455,
          0.09774573404584759,
          0.09986432911968283,
          0.10208183357814886,
          0.10442193402058339,
          0.10671912595031506,
          0.10915433044070104,
          0.11171172826181805,
          0.11425529108007765,
          0.11689806419165615,
          0.1196060619598616,
          0.12236114793889082,
          0.12525210194085754,
          0.12802725335285126,
          0.131107262031908,
          0.1342069923066418,
          0.13728703449002405,
          0.14043975903614458,
          0.1436938502010225,
          0.14698303697593976,
          0.15037182924178452,
          0.15355637459528804,
          0.1571233691279863,
          0.16066416031057648,
          0.1643891692344334,
          0.1681658133062718,
          0.17189784501938846,
          0.17564771943650873,
          0.1796501710105322,
          0.18369281820336572,
          0.1878795040541032,
          0.1925547266262367,
          0.1972406494664537,
          0.2017229805325576,
          0.20656969748147522,
          0.21107820555007129,
          0.21596367328777283,
          0.2209013716525147,
          0.22603655818100757,
          0.23126017415570657,
          0.2364019278279535,
          0.24232790776534419,
          0.2477198697068404,
          0.2538417315371588,
          0.2596989612041552,
          0.2658397011959017,
          0.2726402312347575,
          0.27948830381484374,
          0.28668969557400564,
          0.29395115466260696,
          0.3014519842264822,
          0.308488160291439,
          0.31608243152280846,
          0.32478774762776763,
          0.3332045643646737,
          0.3429799794661191,
          0.3524007626971746,
          0.3620178041543027,
          0.3722269886015443,
          0.38306740767300107,
          0.3964306901324896,
          0.4080729735634695,
          0.41947679736569304,
          0.4331227684702005,
          0.44978916133062624,
          0.4685145317545748,
          0.4876760563380282,
          0.5053501945525292,
          0.5238713399682677,
          0.5458188153310104,
          0.5631005765534913,
          0.5812768240343348,
          0.6048642932675361,
          0.6283396946564885,
          0.6568758344459279,
          0.6833503575076609,
          0.7152428810720268,
          0.7477477477477478,
          0.7972972972972973,
          0.8382352941176471,
          0.9166666666666666,
          1,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        },
        {
         "name": "recall",
         "type": "scatter",
         "x": [
          0,
          0.010101010101010102,
          0.020202020202020204,
          0.030303030303030304,
          0.04040404040404041,
          0.05050505050505051,
          0.06060606060606061,
          0.07070707070707072,
          0.08080808080808081,
          0.09090909090909091,
          0.10101010101010102,
          0.11111111111111112,
          0.12121212121212122,
          0.13131313131313133,
          0.14141414141414144,
          0.15151515151515152,
          0.16161616161616163,
          0.17171717171717174,
          0.18181818181818182,
          0.19191919191919193,
          0.20202020202020204,
          0.21212121212121213,
          0.22222222222222224,
          0.23232323232323235,
          0.24242424242424243,
          0.25252525252525254,
          0.26262626262626265,
          0.27272727272727276,
          0.2828282828282829,
          0.29292929292929293,
          0.30303030303030304,
          0.31313131313131315,
          0.32323232323232326,
          0.33333333333333337,
          0.3434343434343435,
          0.3535353535353536,
          0.36363636363636365,
          0.37373737373737376,
          0.38383838383838387,
          0.393939393939394,
          0.4040404040404041,
          0.4141414141414142,
          0.42424242424242425,
          0.43434343434343436,
          0.4444444444444445,
          0.4545454545454546,
          0.4646464646464647,
          0.4747474747474748,
          0.48484848484848486,
          0.494949494949495,
          0.5050505050505051,
          0.5151515151515152,
          0.5252525252525253,
          0.5353535353535354,
          0.5454545454545455,
          0.5555555555555556,
          0.5656565656565657,
          0.5757575757575758,
          0.5858585858585859,
          0.595959595959596,
          0.6060606060606061,
          0.6161616161616162,
          0.6262626262626263,
          0.6363636363636365,
          0.6464646464646465,
          0.6565656565656566,
          0.6666666666666667,
          0.6767676767676768,
          0.686868686868687,
          0.696969696969697,
          0.7070707070707072,
          0.7171717171717172,
          0.7272727272727273,
          0.7373737373737375,
          0.7474747474747475,
          0.7575757575757577,
          0.7676767676767677,
          0.7777777777777778,
          0.787878787878788,
          0.797979797979798,
          0.8080808080808082,
          0.8181818181818182,
          0.8282828282828284,
          0.8383838383838385,
          0.8484848484848485,
          0.8585858585858587,
          0.8686868686868687,
          0.8787878787878789,
          0.888888888888889,
          0.8989898989898991,
          0.9090909090909092,
          0.9191919191919192,
          0.9292929292929294,
          0.9393939393939394,
          0.9494949494949496,
          0.9595959595959597,
          0.9696969696969697,
          0.9797979797979799,
          0.98989898989899,
          1
         ],
         "xaxis": "x",
         "y": [
          1,
          1,
          0.9999194360523666,
          0.9998388721047331,
          0.999718026183283,
          0.9995568982880161,
          0.999154078549849,
          0.9988721047331319,
          0.9985095669687815,
          0.9980664652567975,
          0.9974622356495468,
          0.9967774420946627,
          0.9957703927492447,
          0.9950453172205438,
          0.9934340382678751,
          0.991742195367573,
          0.9903323262839879,
          0.9881973816717019,
          0.9866263846928499,
          0.9844511581067472,
          0.9819536757301107,
          0.9798187311178248,
          0.9768378650553877,
          0.9737361530715005,
          0.9705941591137965,
          0.9666062437059416,
          0.963141993957704,
          0.9582678751258812,
          0.9543605236656596,
          0.9500503524672709,
          0.9448942598187311,
          0.9390936555891238,
          0.9329305135951662,
          0.9260020140986909,
          0.9195971802618328,
          0.9112990936555891,
          0.9047331319234643,
          0.8968781470292044,
          0.8897079556898289,
          0.8811278952668681,
          0.8714199395770392,
          0.8618731117824774,
          0.8526888217522659,
          0.8429003021148036,
          0.832588116817724,
          0.8223967774420947,
          0.8108358509566969,
          0.7989123867069486,
          0.7883182275931521,
          0.7751863041289023,
          0.7624974823766365,
          0.7492849949647533,
          0.7352265861027191,
          0.7210473313192346,
          0.7053776435045317,
          0.6908761329305136,
          0.6739577039274924,
          0.658086606243706,
          0.6414904330312186,
          0.6250151057401813,
          0.6079355488418933,
          0.5905337361530715,
          0.5716817724068479,
          0.5522255790533737,
          0.5327291037260826,
          0.5116616314199396,
          0.4918026183282981,
          0.47154078549848943,
          0.4516817724068479,
          0.43061430010070495,
          0.4094662638469285,
          0.38823766364551865,
          0.3670090634441088,
          0.34429003021148036,
          0.32302114803625376,
          0.30094662638469283,
          0.2770996978851964,
          0.25409869083585096,
          0.23202416918429003,
          0.210392749244713,
          0.18968781470292045,
          0.16741188318227593,
          0.14630412890231623,
          0.12620342396777443,
          0.10622356495468278,
          0.08729103726082578,
          0.06912386706948641,
          0.05305135951661631,
          0.03963746223564955,
          0.026948640483383687,
          0.017200402819738166,
          0.010030211480362539,
          0.004753272910372608,
          0.00229607250755287,
          0.0008862034239677744,
          0.00016112789526686808,
          0,
          0,
          0,
          0
         ],
         "yaxis": "y"
        },
        {
         "name": "gain",
         "type": "scatter",
         "x": [
          0,
          0.010101010101010102,
          0.020202020202020204,
          0.030303030303030304,
          0.04040404040404041,
          0.05050505050505051,
          0.06060606060606061,
          0.07070707070707072,
          0.08080808080808081,
          0.09090909090909091,
          0.10101010101010102,
          0.11111111111111112,
          0.12121212121212122,
          0.13131313131313133,
          0.14141414141414144,
          0.15151515151515152,
          0.16161616161616163,
          0.17171717171717174,
          0.18181818181818182,
          0.19191919191919193,
          0.20202020202020204,
          0.21212121212121213,
          0.22222222222222224,
          0.23232323232323235,
          0.24242424242424243,
          0.25252525252525254,
          0.26262626262626265,
          0.27272727272727276,
          0.2828282828282829,
          0.29292929292929293,
          0.30303030303030304,
          0.31313131313131315,
          0.32323232323232326,
          0.33333333333333337,
          0.3434343434343435,
          0.3535353535353536,
          0.36363636363636365,
          0.37373737373737376,
          0.38383838383838387,
          0.393939393939394,
          0.4040404040404041,
          0.4141414141414142,
          0.42424242424242425,
          0.43434343434343436,
          0.4444444444444445,
          0.4545454545454546,
          0.4646464646464647,
          0.4747474747474748,
          0.48484848484848486,
          0.494949494949495,
          0.5050505050505051,
          0.5151515151515152,
          0.5252525252525253,
          0.5353535353535354,
          0.5454545454545455,
          0.5555555555555556,
          0.5656565656565657,
          0.5757575757575758,
          0.5858585858585859,
          0.595959595959596,
          0.6060606060606061,
          0.6161616161616162,
          0.6262626262626263,
          0.6363636363636365,
          0.6464646464646465,
          0.6565656565656566,
          0.6666666666666667,
          0.6767676767676768,
          0.686868686868687,
          0.696969696969697,
          0.7070707070707072,
          0.7171717171717172,
          0.7272727272727273,
          0.7373737373737375,
          0.7474747474747475,
          0.7575757575757577,
          0.7676767676767677,
          0.7777777777777778,
          0.787878787878788,
          0.797979797979798,
          0.8080808080808082,
          0.8181818181818182,
          0.8282828282828284,
          0.8383838383838385,
          0.8484848484848485,
          0.8585858585858587,
          0.8686868686868687,
          0.8787878787878789,
          0.888888888888889,
          0.8989898989898991,
          0.9090909090909092,
          0.9191919191919192,
          0.9292929292929294,
          0.9393939393939394,
          0.9494949494949496,
          0.9595959595959597,
          0.9696969696969697,
          0.9797979797979799,
          0.98989898989899,
          1
         ],
         "xaxis": "x",
         "y": [
          0,
          84,
          906,
          2984,
          6562,
          11768,
          18216,
          26164,
          35066,
          44556,
          54514,
          65132,
          75792,
          86620,
          97852,
          108806,
          119774,
          130872,
          141922,
          152384,
          162994,
          173532,
          183634,
          193624,
          203356,
          212858,
          222252,
          230966,
          240012,
          248670,
          256884,
          264878,
          272690,
          280180,
          287436,
          293944,
          300752,
          307140,
          313450,
          319462,
          325022,
          330250,
          335480,
          340396,
          345126,
          350060,
          354564,
          358482,
          362486,
          365710,
          368972,
          371924,
          374650,
          377118,
          379108,
          381382,
          382814,
          384448,
          385580,
          386582,
          387516,
          388136,
          388420,
          388356,
          388080,
          387196,
          386378,
          385510,
          384374,
          383066,
          381412,
          379532,
          377500,
          375062,
          372894,
          370158,
          366872,
          363690,
          360630,
          357502,
          354318,
          350546,
          346840,
          343238,
          339400,
          335670,
          332040,
          328734,
          325934,
          323192,
          321052,
          319444,
          318242,
          317670,
          317338,
          317162,
          317122,
          317122,
          317122,
          317122
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Gain versus précision/recall"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "title": {
          "text": "Seuil de probabilité"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "scores"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right",
         "title": {
          "text": "gain"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_gain_scores(threshold_array, gain_scores, accuracy_scores,recall_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On recalcule les scores avec le nouveau seuil de probabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_with_threshold(best_model,X_train, y_train, best_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance globale des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle Light GBM permet de récupérer l'attribut feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df['importance'] = model['lgbm'].feature_importances_\n",
    "feature_importance_df.index = features\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by='importance', ascending=False)\n",
    "\n",
    "most_important_features = list(feature_importance_df.nlargest(20, columns=['importance']).index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de visualisation des features les plus influentes, à l'échelle globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_global_importance(feature_importance_df, num_features):\n",
    "    df = feature_importance_df.nlargest(num_features, columns=['importance'])\n",
    "    fig = px.bar(df, orientation='h')\n",
    "    fig.update_yaxes(title='Importance')\n",
    "    fig.update_xaxes(title='Feature')\n",
    "    fig.update_traces(showlegend=False)\n",
    "    fig.update_layout(\n",
    "    title=\"Importance globale des features\",\n",
    "    font_size=11,\n",
    "    height=800,\n",
    "    width=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_global_importance(feature_importance_df, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi visualiser les influences locales respectives sur un sous-ensemble de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sample = get_small_sample_for_testing(data,0.01)\n",
    "small_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_small_sample = small_sample[['TARGET']]\n",
    "X_small_sample = small_sample.drop(columns=['SK_ID_CURR','TARGET'])\n",
    "features = X_sample.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM permet grâce à un paramètre (pred_contrib) de calculer les valeurs SHAP de chaque features, par individu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap_values= model.predict(X_small_sample.values,pred_contrib=True)\n",
    "shap_df = pd.DataFrame(shap_values[:,0:len(features)], columns=features)\n",
    "shap_best_df = shap_df[most_important_features]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des valeurs shap par individu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bee_chart(shap_best_df) :\n",
    "\n",
    "    df = pd.melt(shap_best_df, value_vars=shap_best_df.columns).rename(columns={\n",
    "        \"variable\": \"features\",\n",
    "        \"value\": \"shap_value\"\n",
    "    })\n",
    "    fig = px.scatter(df, y=\"features\", x=\"shap_value\", color='shap_value')\n",
    "    fig.update_traces(marker_size=3)\n",
    "    fig.update_layout(\n",
    "        title=\"Influences locales des features pour chaque point\",\n",
    "        font_size=11,\n",
    "        height=800,\n",
    "        width=800)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bee_chart(shap_best_df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "290f74c997349af89a0ac2887adbe9207b00d880f9dc68d43a0e78595c455d8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
